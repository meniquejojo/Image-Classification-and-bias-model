{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e1e84a-aebf-4e1b-b4be-ff5a23103d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf_env/lib/python3.11/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "625b97dc-5911-457f-8d7f-1dae772d2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train,validation,test)= tfds.load(\"celeb_a\", split=['train','validation','test'], as_supervised=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aaa9a42-1f4c-470e-83c9-83e390efb32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64\n",
    "def preprocess(sample):\n",
    "    image = sample['image']\n",
    "    image = tf.image.resize(image,[IMG_SIZE, IMG_SIZE])\n",
    "    #Normalization\n",
    "    image = image/255.0\n",
    "    # Finetune atrribute\n",
    "    # Convert directly to int32\n",
    "    label = tf.cast(sample['attributes']['Smiling'], tf.int32)\n",
    "    \n",
    "    label = tf.where(label == -1, 0, label)\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee9285e0-ed1f-4b05-9d77-f58fe798784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "BUFFER_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1df2cf7f-3121-4bfa-a314-2f4a1eed9ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch the dataset \n",
    "\n",
    "train_batches = (\n",
    "    train\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "validation_batches = (\n",
    "    validation\n",
    "    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "testing_batches = (\n",
    "    test\n",
    "    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078249ed-5a41-4177-99f8-cdaeaddfba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_batches))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d23bfca-c3ba-4265-8779-59d8a866e3e1",
   "metadata": {},
   "source": [
    "Dataset Exploratory Analysis & Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb2cba6-e46c-4f64-8f10-6f1d11c520d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to count data\n",
    "def attribute_counts(raw_train,raw_validation,raw_test):\n",
    "    counter = Counter()\n",
    "    for i in raw_train:\n",
    "        male = int(i['attributes']['Male']  )    # Male label\n",
    "        smiling = int(i['attributes']['Smiling'])# Smiling label\n",
    "        counter[(male,smiling)]+=1\n",
    "    for i in raw_test:\n",
    "        male = int(i['attributes']['Male']  )    # Male label\n",
    "        smiling = int(i['attributes']['Smiling'])# Smiling label\n",
    "        counter[(male,smiling)]+=1\n",
    "    for i in raw_validation:\n",
    "        male = int(i['attributes']['Male']  )    # Male label\n",
    "        smiling = int(i['attributes']['Smiling'])# Smiling label\n",
    "        counter[(male,smiling)]+=1\n",
    "    return counter\n",
    "    \n",
    "counts=attribute_counts(train,validation,test)\n",
    "print('The number of females smiling: ',counts[(0,1)] )\n",
    "print('The number of females not smiling:',counts[(0,0)])\n",
    "print('The total number of females: ', counts[(0,1)]+counts[(0,0)])\n",
    "print('The number of males smiling:' ,counts[(1,1)])\n",
    "print('The number of males not smiling:', counts[(1,0)])\n",
    "print('The total number of males:', counts[(1,1)]+counts[(1,0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da292e3d-19f8-4457-952b-4ff2327ed229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attribute counts\n",
    "def plot_attributes(counts):\n",
    "    # Extract counts\n",
    "    female_smiling = counts[(0,1)]\n",
    "    female_notsmiling = counts[(0,0)]\n",
    "    female_total = female_smiling + female_notsmiling\n",
    "\n",
    "    male_smiling = counts[(1,1)]\n",
    "    male_notsmiling = counts[(1,0)]\n",
    "    male_total = male_smiling + male_notsmiling\n",
    "\n",
    "    # Create figure\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "    categories = [\"Female\", \"Male\"]\n",
    "    colors = [\"#8B5A2B\", \"#2E8B57\"]  # Brown (Female), Green (Male)\n",
    "\n",
    "    ax1.set_title(\"Smiling Images by Gender\", fontsize=14)\n",
    "    values1 = [female_smiling, male_smiling]\n",
    "    bars1 = ax1.bar(categories, values1, color=colors)\n",
    "    ax1.set_ylabel(\"Number of Images\")\n",
    "\n",
    "    # Add value labels\n",
    "    for bar in bars1:\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2,\n",
    "                 bar.get_height(),\n",
    "                 f\"{bar.get_height():,}\",\n",
    "                 ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    # --- Plot 2: Not Smiling ---\n",
    "    ax2.set_title(\"Non-Smiling Images by Gender\", fontsize=14)\n",
    "    values2 = [female_notsmiling, male_notsmiling]\n",
    "    bars2 = ax2.bar(categories, values2, color=colors)\n",
    "    ax2.set_ylabel(\"Number of Images\")\n",
    "\n",
    "    for bar in bars2:\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2,\n",
    "                 bar.get_height(),\n",
    "                 f\"{bar.get_height():,}\",\n",
    "                 ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    ax3.set_title(\"Overall Gender Distribution\", fontsize=14)\n",
    "    values3 = [female_total, male_total]\n",
    "    bars3 = ax3.bar(categories, values3, color=colors)\n",
    "    ax3.set_ylabel(\"Number of Images\")\n",
    "\n",
    "    for bar in bars3:\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2,\n",
    "                 bar.get_height(),\n",
    "                 f\"{bar.get_height():,}\",\n",
    "                 ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    # Overall title\n",
    "    fig.suptitle(\"Gender and Smiling Attribute Distribution in CelebA\",\n",
    "                 fontsize=18)\n",
    "\n",
    "    fig.tight_layout()\n",
    "plot_attributes(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b82263d-b29f-4454-84e0-30d36ab644aa",
   "metadata": {},
   "source": [
    "Dataset Interpretation\n",
    "\n",
    "Among smiling images, female subjects constitute a 65% proportion of the dataset, while male smiling subjects account for 35%, This imbalance suggests that the classifier may learn smiling-related features more effectively for female faces than for male faces.\n",
    "\n",
    "A similar imbalance is observed in non-smiling images, indicating that the gender skew is consistent across facial expression categories rather than isolated to smiling alone.\n",
    "\n",
    "Overall, female images represent a higher proportion of the dataset than male images. As a result, accuracy may overestimate model performance if subgroup-level disparities are not examined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1d09c60d-c940-4821-a7c0-8647f255751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing pipelines\n",
    "\n",
    "IMG_SIZE = 64\n",
    "def preprocess(sample):\n",
    "    image = sample['image']\n",
    "    image = tf.image.resize(image,[IMG_SIZE, IMG_SIZE])\n",
    "    #Normalization\n",
    "    image = image/255.0\n",
    "    # Finetune atrribute\n",
    "    # Convert directly to int32\n",
    "    label = tf.cast(sample['attributes']['Smiling'], tf.int32)\n",
    "    \n",
    "    label = tf.where(label == -1, 0, label)\n",
    "    return image,label\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b9e3e348-90ee-4926-8bf7-cbb1ff2f0908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Visualization\n",
    "def show_images(dataset):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    for i, (image, label) in enumerate(dataset.take(25)):\n",
    "        ax = plt.subplot(5, 5, i + 1)   \n",
    "        plt.imshow(image)\n",
    "        graph_label= tf.where(label==0,False,True)\n",
    "        plt.title(f\"Smiling: {graph_label.numpy()}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e2cf4a-5378-40a0-989e-020c7baab61e",
   "metadata": {},
   "source": [
    "\n",
    "We used a three-block convolutional architecture, which provides sufficient capacity to learn expression-level features while minimizing overfitting and maintaining interpretability for bias analysis.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7f09560c-952c-4453-a13d-56b3dcb5c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(\n",
    "    input_shape=(64, 64, 3), # width heigh channels\n",
    "    num_classes=1,\n",
    "    learning_rate=1e-3\n",
    "):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bd94912d-a38c-4a57-9273-a847e30046a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training model parameters\n",
    "#defining models\n",
    "model = build_cnn_model()\n",
    "# creatingcallbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience =3, mode='min', restore_best_weights=True)\n",
    "# defining max_epochs\n",
    "epoch= 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e230bb-81d8-4a67-aca0-1ca2e1da0e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "#creating training function\n",
    "def train_model(model, train_data, val_data, max_epochs, callbacks):\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        validation_data=val_data,\n",
    "        epochs=max_epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    return model, history\n",
    "          \n",
    "sanity_model, sanity_history = train_model(\n",
    "    model=model,\n",
    "    train_data=train_batches,\n",
    "    val_data=validation_batches,\n",
    "    max_epochs=1,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fdc772-59d5-4156-92e3-38cf639e1c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3d7a37-d4ad-4761-bee8-b1b02d76a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subgroup Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92277e23-91d5-4a66-bde9-d463c7f24d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa265249-e386-4912-9e3b-2b5e589e3eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of males smiling  6157\n",
      "The number of males not smiling  5252\n",
      "The number of females smiling 3445\n",
      "The number of females not smiling  5013\n"
     ]
    }
   ],
   "source": [
    "def attribute_counts(dataset):\n",
    "    counter = Counter()\n",
    "    for i in dataset:\n",
    "        male = int(i['attributes']['Male']  )    # Male label\n",
    "        smiling = int(i['attributes']['Smiling'])# Smiling label\n",
    "        counter[(male,smiling)]+=1\n",
    "    print('The number of males smiling ',counter[(0,1)] )\n",
    "    print('The number of males not smiling ',counter[(0,0)])\n",
    "    print('The number of females smiling' ,counter[(1,1)])\n",
    "    print('The number of females not smiling ', counter[(1,0)])\n",
    "        \n",
    "attribute_counts(validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c1d390-6d95-42f6-8a47-428cc982df35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
